### 项目名称

#### 离线数据仓库系统

### 技术栈

Hadoop (HDFS, MapReduce/YARN), Kafka, Zookeeper, Flume, Maxwell, DataX, Hive, Spark (Core/SQL), DolphinScheduler, Nginx, MySQL

### 项目描述

随着公司业务数据以及日志采集系统数据逐渐增加，要对公司数据进行集中处理，需要搭建一个统一的数据管理仓库，将公司的业务数据和日志数据进行统一的管理和分析，为公司的日常运营，业务发展提供相应的决策分析处理依据。

### 责任描述

1. 熟悉公司数仓体系架构，对公司数据域、指标体系构建和落地标准进行学习，熟悉数据表字段以及业务逻辑。
2. 运用 DataX 实现业务数据库（如MySQL）的全量数据高效同步，并结合 Maxwell 实时捕获增量数据变更，保证ODS层数据的准实时性。
3. 基于 HiveQL 及 Spark SQL/Spark Core 开发各数据层（ODS->DWD, DWD->DWS, DWS->ADS）的ETL脚本，完成数据清洗、转换、聚合等复杂处理逻辑。
4. 参与部分指标的辨析，用户留存率，流量域路径分析，书店成交率，书店发货时间，书店优惠总天数，书店直播间流量等指标分析。使用关联规则挖掘（Apriori算法）发现商品间的潜在联系； 从而为提升用户复购率、优化营销活动策略、或进行用户流失预警与风险防控等场景提供了关键数据洞察与决策支持。
5. 负责调度任务的监控，保证调度任务正常执行，完成每日指标的监控。

### 项目成果

1. 使用 Nginx 负载均衡实现数据的采集，对业务数据以及埋点日志数据分发到不同的日志服务器，存储为文件，并以天为单位进行存储，对数据做 30 天的保存；
2.  对表类型进行筛选，使用 DataX 进行全量表同步，使用 Maxwell 对增量表进行同步； 
3. 根据维度建模理论对数据仓库进行搭建，对数仓进行分层处理，数仓主要分为原始数据层 ODS、公共维度层 DIM、明细数据层 DWD、汇总数据层 DWS、数据应用层 ADS； 
4. 对所需指标进行指标拆分，构建指标体系，完成指标的构建； 
5. 通过 DataX 将 ADS 层指标导入 MySQL，作为最终数据源，供业务报表以及业务可视化进行使用； 
6. 构建每层的数据导入和分析脚本，并使用 DolphinScheduler 进行调度，完成对调度任务监控的配置。

